{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saramazz/Edtech-LearnOktopus/blob/main/Learn_Oktopus_v.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SETUP"
      ],
      "metadata": {
        "id": "OqRYAJO6fhlE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iOF6Yo-wUEC"
      },
      "source": [
        "### Set environment variables\n",
        "\n",
        "Set environment variables for `KAGGLE_USERNAME` and `KAGGLE_KEY`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0_EdOg9DPK6Q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Note: `userdata.get` is a Colab API. If you're not using Colab, set the env\n",
        "# vars as appropriate for your system.\n",
        "\n",
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get('KAGGLE_USERNAME')\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get('KAGGLE_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuEUAKJW1QkQ"
      },
      "source": [
        "### Install dependencies\n",
        "\n",
        "Install Keras, KerasNLP, and other dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1eeBtYqJsZPG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5080d0d7-d7ac-4cc3-c11e-fd9cdecdf029"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.4/508.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install Keras 3 last. See https://keras.io/getting_started/ for more details.\n",
        "!pip install -q -U keras-nlp\n",
        "!pip install -q -U keras>=3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yake"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBcl3f4YlnLZ",
        "outputId": "f368e210-2035-4618-bcdd-d56a15837a9b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yake\n",
            "  Downloading yake-0.4.8-py2.py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from yake) (0.9.0)\n",
            "Requirement already satisfied: click>=6.0 in /usr/local/lib/python3.10/dist-packages (from yake) (8.1.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from yake) (1.25.2)\n",
            "Collecting segtok (from yake)\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from yake) (3.3)\n",
            "Collecting jellyfish (from yake)\n",
            "  Downloading jellyfish-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from segtok->yake) (2023.12.25)\n",
            "Installing collected packages: segtok, jellyfish, yake\n",
            "Successfully installed jellyfish-1.0.3 segtok-1.5.11 yake-0.4.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select GEMMA backend"
      ],
      "metadata": {
        "id": "M1-F-7KwfEWA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yn5uy8X8sdD0"
      },
      "outputs": [],
      "source": [
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # Or \"torch\" or \"tensorflow\".\n",
        "# Avoid memory fragmentation on JAX backend.\n",
        "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZs8XXqUKRmi"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FYHyPUA9hKTf"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import keras_nlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RCE3fdGhDE5"
      },
      "source": [
        "# Load GEMMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vz5zLEyLstfn",
        "outputId": "13b3aa4e-a95b-4e5f-8faa-7dbe6b46cebf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Attaching 'config.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Colab notebook...\n",
            "Attaching 'config.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Colab notebook...\n",
            "Attaching 'model.weights.h5' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Colab notebook...\n",
            "Attaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Colab notebook...\n",
            "Attaching 'assets/tokenizer/vocabulary.spm' from model 'keras/gemma/keras/gemma_1.1_instruct_2b_en/3' to your Colab notebook...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                   │                                             \u001b[38;5;34m256,000\u001b[0m │\n",
              "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
              "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,506,172,416\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_1.1_instruct_2b_en\")\n",
        "gemma_lm.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example Document"
      ],
      "metadata": {
        "id": "bDEOk9agfqiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"In April 2024, heavy rain severely impacted states in the Persian Gulf, causing flash flooding across the region. Several states recorded nearly a year's worth of rain in a single day. The floods had a significant impact across the region, with Oman and the United Arab Emirates being particularly affected,[1] resulting in the deaths of at least 32 people, including 19 in Oman and 8 in Iran.[2][3] Southeastern Iran, Yemen, Bahrain, Qatar, and the Eastern Province of Saudi Arabia also experienced heavy rainfall and subsequent flooding.\""
      ],
      "metadata": {
        "id": "5PzyeZMHNgSo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ESTRAZIONE KEYWORDS"
      ],
      "metadata": {
        "id": "q6DmO16OlcVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yake\n",
        "kw_extractor = yake.KeywordExtractor()\n",
        "language = \"en\"\n",
        "max_ngram_size = 3\n",
        "deduplication_threshold = 0.4\n",
        "numOfKeywords = 10\n",
        "custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold, top=numOfKeywords, features=None)\n",
        "keywords = custom_kw_extractor.extract_keywords(text)\n",
        "for kw in keywords:\n",
        "  print(kw[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aip3IX71ldpJ",
        "outputId": "0c8d9608-5ee5-4992-88a6-8d5f99da5699"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Persian Gulf\n",
            "rain severely impacted\n",
            "causing flash flooding\n",
            "heavy rain severely\n",
            "United Arab Emirates\n",
            "impacted states\n",
            "Southeastern Iran\n",
            "April\n",
            "Gulf\n",
            "Eastern Province\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DESCRIZIONE KEYWORDS"
      ],
      "metadata": {
        "id": "uuVikHGTcNLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template_kw_desc = \"Provide a a short title to describe a paragraph speaking about {keyword}. \\n\\n ### TITLE:\\n\"\n",
        "\n",
        "for k in keywords:\n",
        "  prompt = template_kw_desc.format(\n",
        "    keyword=k[0],\n",
        "  )\n",
        "\n",
        "  sampler = keras_nlp.samplers.TopKSampler(k=3, seed=2)\n",
        "  gemma_lm.compile(sampler=sampler)\n",
        "  res = gemma_lm.generate(prompt, max_length=50)\n",
        "  print(res)\n",
        "  print('\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol3Q0gl-cL4g",
        "outputId": "ac831451-3e0e-44c7-8872-d94c76d1d279"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Provide a a short title to describe a paragraph speaking about Persian Gulf. \n",
            "\n",
            " ### TITLE:\n",
            "**Exploring the Persian Gulf: A Region of Riches and Challenges**\n",
            "\n",
            "\n",
            "\n",
            "Provide a a short title to describe a paragraph speaking about rain severely impacted. \n",
            "\n",
            " ### TITLE:\n",
            "**Rain-Ravaged Landscapes: The Devastation Caused by Severe Rainfall**\n",
            "\n",
            "\n",
            "\n",
            "Provide a a short title to describe a paragraph speaking about causing flash flooding. \n",
            "\n",
            " ### TITLE:\n",
            "**The Power of Flash Flooding: How to Cause It and Its Consequences**\n",
            "\n",
            "\n",
            "\n",
            "Provide a a short title to describe a paragraph speaking about heavy rain severely. \n",
            "\n",
            " ### TITLE:\n",
            "**The Heavy Rain**\n",
            "\n",
            "**Paragraph:**\n",
            "\n",
            "Heavy rain severely affected the city, causing widespread flooding and damage to infrastructure. Streets were inundated\n",
            "\n",
            "\n",
            "\n",
            "Provide a a short title to describe a paragraph speaking about United Arab Emirates. \n",
            "\n",
            " ### TITLE:\n",
            "**United Arab Emirates: Economic Powerhouse and Cultural Tapestry**\n",
            "\n",
            "\n",
            "\n",
            "Provide a a short title to describe a paragraph speaking about impacted states. \n",
            "\n",
            " ### TITLE:\n",
            "**States Impacted: Exploring the Economic Consequences and Policy Responses**\n",
            "\n",
            "\n",
            "\n",
            "Provide a a short title to describe a paragraph speaking about Southeastern Iran. \n",
            "\n",
            " ### TITLE:\n",
            "**Exploring Southeastern Iran: Culture, History, and Challenges**\n",
            "\n",
            "\n",
            "\n",
            "Provide a a short title to describe a paragraph speaking about April. \n",
            "\n",
            " ### TITLE:\n",
            "**April's Blooming Elegance**\n",
            "\n",
            "\n",
            "\n",
            "Provide a a short title to describe a paragraph speaking about Gulf. \n",
            "\n",
            " ### TITLE:\n",
            "**Exploring the Diverse Landscape of the Gulf**\n",
            "\n",
            "**Paragraph:**\n",
            "\n",
            "The Gulf is a vast body of water located in the western part of North America\n",
            "\n",
            "\n",
            "\n",
            "Provide a a short title to describe a paragraph speaking about Eastern Province. \n",
            "\n",
            " ### TITLE:\n",
            "**Exploring the Eastern Province's Rich Tapestry of Cultures and Landscapes**\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DOMANDE TEST INGRESSO"
      ],
      "metadata": {
        "id": "p84xohpQt0OP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "concept = 'heavy rain'\n",
        "document = text\n",
        "template = 'Provide one and only one simple question realted to the following document and to the concept {concept}. It must have one correct answer and three wrong answers. Use the format # Question: question, # Correct Answer: answer 1. # Wrong Answers: answer 2, answer3, answer4.  \\n\\n ### DOCUMENT: {document}\\n\\n### QUESTIONS:\\n{response}'\n",
        "\n",
        "prompt = template.format(\n",
        "    concept=concept,\n",
        "    document=text,\n",
        "    response=\"\",\n",
        ")\n",
        "\n",
        "sampler = keras_nlp.samplers.TopKSampler(k=30, seed=2)\n",
        "gemma_lm.compile(sampler=sampler)\n",
        "res = gemma_lm.generate(prompt, max_length=500)\n",
        "i = res.rfind('?')\n",
        "#res = res[:i+1]\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThdLkFykt1z6",
        "outputId": "54f1c7c3-6e83-4555-c8bf-5b3101bf7494"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Provide one and only one simple question realted to the following document and to the concept heavy rain. It must have one correct answer and three wrong answers. Use the format # Question: question, # Correct Answer: answer 1. # Wrong Answers: answer 2, answer3, answer4.  \n",
            "\n",
            " ### DOCUMENT: In April 2024, heavy rain severely impacted states in the Persian Gulf, causing flash flooding across the region. Several states recorded nearly a year's worth of rain in a single day. The floods had a significant impact across the region, with Oman and the United Arab Emirates being particularly affected,[1] resulting in the deaths of at least 32 people, including 19 in Oman and 8 in Iran.[2][3] Southeastern Iran, Yemen, Bahrain, Qatar, and the Eastern Province of Saudi Arabia also experienced heavy rainfall and subsequent flooding.\n",
            "\n",
            "### QUESTIONS:\n",
            "1. **What was the impact of heavy rain on the region?**\n",
            "A. Increased economic activity\n",
            "B. Significant flash flooding\n",
            "C. Reduced water availability\n",
            "D. All of the above\n",
            "\n",
            "\n",
            "**Answer: B**\n",
            "\n",
            "\n",
            "2. **Which states were particularly affected by the heavy rain?**\n",
            "A. Oman and the United Arab Emirates\n",
            "B. Yemen and Bahrain\n",
            "C. Iran and Qatar\n",
            "D. All of the above\n",
            "\n",
            "\n",
            "**Answer: A**\n",
            "\n",
            "\n",
            "3. **What was the estimated number of people killed due to the heavy rain?**\n",
            "A. Under 5\n",
            "B. 15-30\n",
            "C. 32\n",
            "D. Less than 15\n",
            "\n",
            "\n",
            "**Answer: C**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DOMANDE SUI CONCETTI"
      ],
      "metadata": {
        "id": "o8GFIPtxfPHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "concept = 'heavy rain, persian gulf'\n",
        "document = text\n",
        "template = 'Provide a list of questions related to the following document and to the concept {concept}. Each question must have one correct answer and three wrong answers. Use the format # Question: question 1, # Correct Answer: answer 1. # Wrong Answers: answer 2, answer3, answer4.  \\n\\n ### DOCUMENT: {document}\\n\\n### QUESTIONS:\\n{response}'\n",
        "\n",
        "prompt = template.format(\n",
        "    concept=concept,\n",
        "    document=text,\n",
        "    response=\"\",\n",
        ")\n",
        "\n",
        "sampler = keras_nlp.samplers.TopKSampler(k=30, seed=2)\n",
        "gemma_lm.compile(sampler=sampler)\n",
        "res = gemma_lm.generate(prompt, max_length=500)\n",
        "i = res.rfind('?')\n",
        "#res = res[:i+1]\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zzgw_d6fRCF",
        "outputId": "461f0904-afc5-4486-eb56-249d97e5a9f6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Provide a list of questions related to the following document and to the concept heavy rain, persian gulf. Each question must have one correct answer and three wrong answers. Use the format # Question: question 1, # Correct Answer: answer 1. # Wrong Answers: answer 2, answer3, answer4.  \n",
            "\n",
            " ### DOCUMENT: In April 2024, heavy rain severely impacted states in the Persian Gulf, causing flash flooding across the region. Several states recorded nearly a year's worth of rain in a single day. The floods had a significant impact across the region, with Oman and the United Arab Emirates being particularly affected,[1] resulting in the deaths of at least 32 people, including 19 in Oman and 8 in Iran.[2][3] Southeastern Iran, Yemen, Bahrain, Qatar, and the Eastern Province of Saudi Arabia also experienced heavy rainfall and subsequent flooding.\n",
            "\n",
            "### QUESTIONS:\n",
            "1. What was the cause of the heavy rain in the Persian Gulf?\n",
            "A. Heavy volcanic activity\n",
            "B. Heavy rain due to storms\n",
            "C. Heavy rainfall from heavy showers\n",
            "D. Heavy rainfall from the Persian Gulf itself\n",
            "\n",
            "\n",
            "2. What states were particularly affected by the heavy rain?\n",
            "A. Oman and the United Arab Emirates\n",
            "B. Iran, Yemen, Bahrain, Qatar, and the Eastern Province of Saudi Arabia\n",
            "C. Oman, Yemen, Bahrain, Qatar, and Turkmenistan\n",
            "D. Oman and Turkmenistan\n",
            "\n",
            "\n",
            "3. How many people were killed in the flooding?\n",
            "A. 19\n",
            "B. 32\n",
            "C. 8\n",
            "D. 45\n",
            "\n",
            "\n",
            "4. Which country experienced the highest number of deaths?\n",
            "A. Oman\n",
            "B. Iran\n",
            "C. Yemen\n",
            "D. Bahrain\n",
            "\n",
            "\n",
            "5. What region in the Persian Gulf was particularly affected by heavy rainfall and subsequent flooding?\n",
            "A. Southwestern region\n",
            "B. Southeastern region\n",
            "C. Southern region\n",
            "D. Eastern region\n",
            "\n",
            "\n",
            "### ANSWERS:\n",
            "1. C\n",
            "2. B\n",
            "3. B\n",
            "4. A\n",
            "5. B\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ymKgPxIogk-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FLASHCARDS"
      ],
      "metadata": {
        "id": "4A7h4IyAgljr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template_flashcard = \"Provide one sentence to summarize the content of the following document related to the keyword {keyword}. \\n\\n ### DOCUMENT:\\n {document} \\n\\n ### DESCRIPTION:\\n\"\n",
        "\n",
        "for (k,w) in keywords:\n",
        "  prompt = template_flashcard.format(\n",
        "    keyword=k,\n",
        "    document=text,\n",
        "  )\n",
        "\n",
        "  sampler = keras_nlp.samplers.TopKSampler(k=3, seed=2)\n",
        "  gemma_lm.compile(sampler=sampler)\n",
        "  res = gemma_lm.generate(prompt, max_length=200)\n",
        "  i = res.rindex('### DESCRIPTION:\\n')\n",
        "  res = res[i:]\n",
        "  print(k, '---', res)\n",
        "  print('\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccff88e2-42e8-4cb3-ae7c-3463f8e78a5f",
        "id": "FzcKpTKmgljr"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Persian Gulf --- ### DESCRIPTION:\n",
            " The Persian Gulf is the name given to a strategic waterway connecting the Gulf of Oman with the Arabian Sea. The Persian Gulf region is home to many countries, including Oman, Iran, Yemen, and Saudi Arabia.\n",
            "\n",
            "\n",
            "\n",
            "rain severely impacted --- ### DESCRIPTION:\n",
            "The provided document discusses a series of heavy rainfall events in the Persian Gulf region that severely impacted states in the region.\n",
            "\n",
            "\n",
            "\n",
            "causing flash flooding --- ### DESCRIPTION:\n",
            " The floods were caused by heavy rainfall associated with convective thunderstorms in the Persian Gulf region. The intense rainfall caused rapid runoff and flooding in low-lying areas, leading to flash flooding in several states.\n",
            "\n",
            "### KEYWORD:\n",
            "Flash flooding\n",
            "\n",
            "\n",
            "\n",
            "heavy rain severely --- ### DESCRIPTION:\n",
            "The document discusses the heavy rainfall severely impacting states in the Persian Gulf region in April 2024, causing flash flooding and widespread damage.\n",
            "\n",
            "\n",
            "\n",
            "United Arab Emirates --- ### DESCRIPTION:\n",
            " The document provides an overview of the impact of heavy rain on the United Arab Emirates, highlighting the significant casualties and damage caused by the floods.\n",
            "\n",
            "\n",
            "\n",
            "impacted states --- ### DESCRIPTION:\n",
            "The document discusses the impacts of heavy rain on states in the Persian Gulf region.\n",
            "\n",
            "\n",
            "\n",
            "Southeastern Iran --- ### DESCRIPTION:\n",
            "The document highlights the heavy rain and flooding incidents across the Persian Gulf region, particularly in Oman and the United Arab Emirates, resulting in casualties and damage. It also mentions Southeastern Iran, Yemen, Bahrain, Qatar, and the Eastern Province of Saudi Arabia experiencing heavy rainfall and\n",
            "\n",
            "\n",
            "\n",
            "April --- ### DESCRIPTION:\n",
            "The provided document discusses April's heavy rainfall and its impact on various regions in the Persian Gulf region.\n",
            "\n",
            "\n",
            "\n",
            "Gulf --- ### DESCRIPTION:\n",
            " The document provides an overview of the impact of heavy rain on the Gulf region in April 2024, highlighting the severity of the flooding and its consequences.\n",
            "\n",
            "\n",
            "\n",
            "Eastern Province --- ### DESCRIPTION:\n",
            " The document provides a summary of the impact of heavy rain in the Eastern Province of Saudi Arabia during April 2024.\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DEMO"
      ],
      "metadata": {
        "id": "iYITMDHek56g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Suppose we have an example topic and keywords related to it\n",
        "topic_keywords = {\n",
        "    \"Python\": [\"variables\", \"functions\", \"loops\", \"lists\", \"dictionaries\"],\n",
        "    \"Machine Learning\": [\"supervised learning\", \"unsupervised learning\", \"neural networks\", \"regression\", \"classification\"]\n",
        "}\n",
        "\n",
        "# Assuming the user's prior knowledge scores for each keyword (out of 100)\n",
        "user_prior_knowledge = {\n",
        "    \"Python\": {\"variables\": 60, \"functions\": 70, \"loops\": 50, \"lists\": 40, \"dictionaries\": 30},\n",
        "    \"Machine Learning\": {\"supervised learning\": 80, \"unsupervised learning\": 50, \"neural networks\": 60, \"regression\": 70, \"classification\": 40}\n",
        "}\n",
        "\n",
        "# Function to calculate session availability\n",
        "def calculate_sessions(hours_per_day, total_hours, total_sessions):\n",
        "    hours_per_session = total_hours / total_sessions\n",
        "    sessions_available = hours_per_day / hours_per_session\n",
        "    return sessions_available\n",
        "\n",
        "# Function to generate normalized importance scores for keywords\n",
        "def generate_normalized_importance_scores(keywords, weights):\n",
        "    total_weight = sum(weights.values())  # Calcola la somma totale dei pesi\n",
        "    importance_scores = {}\n",
        "    for keyword in keywords:\n",
        "        importance_scores[keyword] = ((weights[keyword] + user_prior_knowledge[topic][keyword]) / 2) / total_weight\n",
        "    return importance_scores\n",
        "\n",
        "# Main function to print the table\n",
        "def print_keywords_table(topic, keywords, prior_knowledge, final_importance):\n",
        "    print(\"Topic:\", topic)\n",
        "    print(\"{:<20} {:<20} {:<20} {:<20}\".format(\"Keyword\", \"Prior Knowledge\", \"Importance Score\", \"Final Importance\"))\n",
        "    for keyword in keywords:\n",
        "        print(\"{:<20} {:<20} {:<20} {:<20}\".format(keyword, prior_knowledge[topic][keyword], keywords[keyword], final_importance[keyword]))\n",
        "\n",
        "# Example inputs\n",
        "topic = \"Python\"\n",
        "hours_per_day = 3\n",
        "total_sessions = 10\n",
        "total_hours = hours_per_day*total_sessions\n",
        "\n",
        "# Define weights for each keyword\n",
        "topic_keywords_weights = {\n",
        "    \"Python\": {\"variables\": 60, \"functions\": 70, \"loops\": 50, \"lists\": 40, \"dictionaries\": 30},\n",
        "    \"Machine Learning\": {\"supervised learning\": 80, \"unsupervised learning\": 50, \"neural networks\": 60, \"regression\": 70, \"classification\": 40}\n",
        "}\n",
        "\n",
        "# Generate importance scores for keywords\n",
        "#keywords_importance = generate_importance_scores(topic_keywords[topic], topic_keywords_weights[topic])\n",
        "keywords_importance=generate_normalized_importance_scores(topic_keywords[topic], topic_keywords_weights[topic])\n",
        "\n",
        "# Calculate final importance scores\n",
        "final_importance = {}\n",
        "for keyword in keywords_importance:\n",
        "    final_importance[keyword] = (keywords_importance[keyword] + user_prior_knowledge[topic][keyword]) / 2\n",
        "\n",
        "# Calculate sessions available\n",
        "sessions_available = calculate_sessions(hours_per_day, total_hours, total_sessions)\n",
        "\n",
        "# Print keywords table\n",
        "print_keywords_table(topic, keywords_importance, user_prior_knowledge, final_importance)\n",
        "\n",
        "print(\"\\nNumber of sessions available to finish within the deadline:\", sessions_available)\n",
        "\n",
        "# Function to print keywords table with normalized coverage percentage\n",
        "def print_normalized_keywords_coverage_table(topic, keywords, prior_knowledge, final_importance):\n",
        "    print(\"Topic:\", topic)\n",
        "    print(\"{:<10} {:<20} {:<30}\".format(\"Lesson\", \"Keywords Covered\", \"Normalized Coverage Percentage\"))\n",
        "    total_prior_knowledge = sum(prior_knowledge[topic].values())  # Calcola la somma totale della conoscenza pregressa\n",
        "    coverage_list = []  # Lista per memorizzare le tuple (lesson_number, keyword, coverage_percentage)\n",
        "    lesson_number = 1\n",
        "    for keyword in keywords:\n",
        "        coverage_percentage = (prior_knowledge[topic][keyword] / total_prior_knowledge) * 100  # Calcola la percentuale di copertura normalizzata\n",
        "        formatted_percentage = \"{:.2f}%\".format(coverage_percentage)  # Formatta la percentuale con due cifre decimali e aggiunge il simbolo \"%\"\n",
        "        coverage_list.append((lesson_number, keyword, formatted_percentage))  # Aggiungi la tupla alla lista\n",
        "        lesson_number += 1\n",
        "    # Ordina la lista in base alla percentuale di copertura in ordine decrescente\n",
        "    coverage_list.sort(key=lambda x: float(x[2][:-1]), reverse=True)\n",
        "    # Stampa la lista ordinata\n",
        "    for lesson_number, keyword, formatted_percentage in coverage_list:\n",
        "        print(\"{:<10} {:<20} {:<30}\".format(lesson_number, keyword, formatted_percentage))\n",
        "\n",
        "# Esempio di input\n",
        "topic = \"Python\"\n",
        "\n",
        "# Stampa la tabella di copertura delle keywords normalizzata ordinata in ordine decrescente di percentuale di copertura\n",
        "print_normalized_keywords_coverage_table(topic, topic_keywords[topic], user_prior_knowledge, final_importance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7VvUOTlk7NH",
        "outputId": "2d85aa34-c3d5-4058-d758-45ce442414f6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: Python\n",
            "Keyword              Prior Knowledge      Importance Score     Final Importance    \n",
            "variables            60                   0.24                 30.12               \n",
            "functions            70                   0.28                 35.14               \n",
            "loops                50                   0.2                  25.1                \n",
            "lists                40                   0.16                 20.08               \n",
            "dictionaries         30                   0.12                 15.06               \n",
            "\n",
            "Number of sessions available to finish within the deadline: 1.0\n",
            "Topic: Python\n",
            "Lesson     Keywords Covered     Normalized Coverage Percentage\n",
            "2          functions            28.00%                        \n",
            "1          variables            24.00%                        \n",
            "3          loops                20.00%                        \n",
            "4          lists                16.00%                        \n",
            "5          dictionaries         12.00%                        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # OLD"
      ],
      "metadata": {
        "id": "1g5Utfuff_Uj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template_keywords = \"Provide me with the most relevant concepts of the following document, based on the list of keywords. \\n\\n ### DOCUMENT:\\n {document}\\n\\n ### KEYWORDS:\\n {keywords}\\n\\n ### CONCEPTS:\\n\\n{response}\""
      ],
      "metadata": {
        "id": "vrGvjVsJPUm-"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keywords = \"\"\"\n",
        "Persian Gulf\n",
        "rain severely impacted\n",
        "causing flash flooding\n",
        "heavy rain severely\n",
        "United Arab Emirates\n",
        "impacted states\n",
        "Southeastern Iran\n",
        "April\n",
        "Gulf\n",
        "Eastern Province\n",
        "\"\"\"\n",
        "\n",
        "prompt = template_keywords.format(\n",
        "    keywords = keywords,\n",
        "    document=text,\n",
        "    response=\"\",\n",
        ")\n",
        "#sampler = keras_nlp.samplers.TopKSampler(k=10, seed=2)\n",
        "sampler = keras_nlp.samplers.TopPSampler(p=0., seed=2)\n",
        "gemma_lm.compile(sampler=sampler)\n",
        "print(gemma_lm.generate(prompt, max_length=500))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJFLBCStPi-I",
        "outputId": "b37a40af-bdc5-4b8b-8036-5dc2828d9be0"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Provide me with the most relevant concepts of the following document, based on the list of keywords. \n",
            "\n",
            " ### DOCUMENT:\n",
            " In April 2024, heavy rain severely impacted states in the Persian Gulf, causing flash flooding across the region. Several states recorded nearly a year's worth of rain in a single day. The floods had a significant impact across the region, with Oman and the United Arab Emirates being particularly affected,[1] resulting in the deaths of at least 32 people, including 19 in Oman and 8 in Iran.[2][3] Southeastern Iran, Yemen, Bahrain, Qatar, and the Eastern Province of Saudi Arabia also experienced heavy rainfall and subsequent flooding.\n",
            "\n",
            " ### KEYWORDS:\n",
            " \n",
            "Persian Gulf\n",
            "rain severely impacted\n",
            "causing flash flooding\n",
            "heavy rain severely\n",
            "United Arab Emirates\n",
            "impacted states\n",
            "Southeastern Iran\n",
            "April\n",
            "Gulf\n",
            "Eastern Province\n",
            "\n",
            "\n",
            " ### CONCEPTS:\n",
            "\n",
            "Heavy rains that cause severe flooding are common in the Persian Gulf region of the world. In April 2024, a series of severe rainstorms hit several countries in this region, resulting in flash flooding and the deaths of 32 people, including 19 in Oman and 8 in Iran. The heavy rains also impacted states in Saudi Arabia, Qatar, and Yemen. In general, Iran is one of the world's major flood-prone countries, with more than 60% of its territory located in flood-prone zones. Severe flooding events are also common in other countries in the region, such as Bahrain and the United Arab Emirates.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template_schedule = \"Provide me with a schedule to learn the following concepts in the next 3 days. List of concepts:{concepts}\\n{response}\""
      ],
      "metadata": {
        "id": "dom9wn6UKvv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concepts = '''The key concepts are:\n",
        "\n",
        "1. Heavy rains caused flash flooding in the region.\n",
        "\n",
        "2. There were many deaths due to flooding in several countries.\n",
        "\n",
        "3. Flooding had a significant impact on the region.\n",
        "\n",
        "4. There was heavy rainfall and flooding in several\n",
        "'''\n",
        "\n",
        "prompt = template.format(\n",
        "    concepts = concepts,\n",
        "    response=\"\",\n",
        ")\n",
        "sampler = keras_nlp.samplers.TopKSampler(k=5, seed=2)\n",
        "gemma_lm.compile(sampler=sampler)\n",
        "print(gemma_lm.generate(prompt, max_length=256))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "0WcEKnAdKuUu",
        "outputId": "bb10fdb3-8d55-428d-9361-e4343992b3a5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'document'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-ca7647cec80f>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m '''\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m prompt = template.format(\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mconcepts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcepts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'document'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}